<!DOCTYPE html>
<html lang="en-us">
    <head>
    
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-140792770-1"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());

        gtag('config', 'UA-140792770-1');
    </script>

    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <title>
        CNNs for NLP &middot; Michael Zhang
    </title>

    
    <script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
  });
  MathJax.Hub.Queue(function() {
    
    
    
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });

  MathJax.Hub.Config({
  
  TeX: { equationNumbers: { autoNumber: "AMS" } }
  });
</script>

    
    <link rel="stylesheet" href="/css/style.css">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Libre+Baskerville:400,400i,700">
    <link href="https://fonts.googleapis.com/css?family=Roboto+Mono" rel="stylesheet">
    
    <link rel="stylesheet" type="text/css" href="/css/life_contributions.css">

    
    <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-mz.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-mz.png">
    <link rel="apple-touch-icon" sizes="180x180" href="/images/favicon-mz.png">
    <link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet">

    
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.0/css/all.css"
        integrity="sha384-lZN37f5QGtY3VHgisS14W3ExzMWZxybE1SJSEsQp9S+oqd12jhcu+A56Ebc1zFSJ" crossorigin="anonymous">

    
    <link href="" rel="alternate" type="application/rss+xml" title="Michael Zhang" />

    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/moment.js/2.12.0/moment.min.js" charset="utf-8"></script>
    <script src="https://d3js.org/d3.v4.min.js" charset="utf-8"></script>
</head>
    <body>
        		<nav class="nav">
			<div class="nav-container">
				<a href="/">
					<h2 class="nav-title">Michael Zhang</h2>
				</a>
				<ul>
    <li><a href="/about">About</a></li>
    <li><a href="/posts">Posts</a></li>
    <li><a href="/projects">Projects</a></li>
    <li><a href="/">Home</a></li>
</ul>
			</div>
		</nav>

        

<main>
	<div class="post">
		<div class="post-info">
    <span>Updated</span><span> on&nbsp;</span><time datetime="2019-02-02 17:25:11 -0500 -0500">February 2, 2019</time>
        

    
</div>
		<h1 class="post-title">CNNs for NLP</h1>
<div class="post-line" style="padding-bottom: 16px"></div>


		
<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
  });
  MathJax.Hub.Queue(function() {
    
    
    
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });

  MathJax.Hub.Config({
  
  TeX: { equationNumbers: { autoNumber: "AMS" } }
  });
</script>

		<div style="margin-bottom: 2em">
			<i>An intuitive look at one 3-letter acronym ML concept applied to another</i>
			
		</div>
		
	    

		

<p>I&rsquo;ve always believed that a better way to learn things is to explain them to others. It&rsquo;s part of why I teach in college. When I started thinking about the merits of a blog, writing about more technical things as a way to ground concepts for myself was definitely a plus. \</p>

<p>This semester, I&rsquo;m taking <a href="https://harvard-ml-courses.github.io/cs287-web/">CS 287R</a>, a class at Harvard that deals with NLP and increasingly deep learning. Aside from this class, there are also</p>

<p>Think of filters as ways to build up higher-level features, which can then aid in classification at the end</p>

<h1 id="location-invariance">Location Invariance</h1>

<ul>
<li>Convolutions just slide over entire image. Doesn&rsquo;t matter where objects occur. Pooling</li>
</ul>

<h1 id="compositionality">Compositionality</h1>

<p>Filters compose local patch of lower-level features to higher level ones. Pixels $\rightarrow$ edges $\rightarrow$ shapes $\rightarrow$ objects</p>

<p>Input for NLP = sentences, documents in a matrix.</p>

<ul>
<li>Each row is one token (word / character)</li>
<li>Vectors are word embeddings (low-dimension representations) or one-hot vectors (word is index in vocab)</li>
<li>e.g. 10 word sentence w/ 100D embedding $\rightarrow 10 \times 100$ as input</li>
</ul>

<p>NLP, use filters that are same width as image. Height / region size is based on number of words (2 - 5) typical.</p>

<ul>
<li>Filters are not usually square then. Also can be variable height. * Feature maps will be (height $\times$ 1). Example:</li>
</ul>

<p>$$7 \times 5 \rightarrow (2 \times 5, 3 \times 5, 4 \times 5) \rightarrow (6 \times 1, 5 \times 1, 4 \times 1) $$</p>

<p>Then max pool $\rightarrow$ takes the largest value. Then concatenate. Final softmax takes this feature, uses it to classify.</p>

<p>Location invariance and compositionality don&rsquo;t apply obviously?</p>

<ul>
<li>It does matter where words are. Also words build up, not obvious how so like pixels to edges.</li>
<li>CNNs still work? Motivation for RNNs</li>
</ul>

<p>Why CNNs</p>

<ul>
<li>Very fast, efficient in representation. Conv filters leran good reps automatically w/o represented entire vocab</li>
</ul>

<h2 id="cnn-parameters">CNN parameters</h2>

<h3 id="zero-padding">Zero Padding</h3>

<p>Can help preserve shape of feature map. In general, output size is
$$n_{\text{out}} = (n_{\text{in}} - n_{\text{filter size}} + 2n_{\text{padding_size}}) / n_{\text{stride}} + 1$$</p>

<ul>
<li>Especially apparent around the edges. How to capture them?</li>
</ul>

<h3 id="stride-size">Stride size</h3>

<p>Larger stride leads to fewer applications of filter and smaller output.</p>

<ul>
<li>Larger stride size helps build model similar to RNN / looks like a tree?</li>
<li>In practice stride is 1</li>
</ul>

<h3 id="pooling">Pooling</h3>

<p>Subsample their input. Common: max operation to each filter. Can also just pool over a window.</p>

<ul>
<li>Fixed size output matrix (req. for classification)

<ul>
<li>1000 filters, with max pooling to each $\rightarrow$ 1000 output (regardless of filter or input size)</li>
</ul></li>
</ul>

<p>Max pool helps retain info for if feature appeared in sentence</p>

<ul>
<li>Lose info on where it appeared. This is still useful, but tradeoff. (Sim. to bag of words). Lose global info about locality, but keep local info caught by filters.</li>
</ul>

<h3 id="channels">Channels</h3>

<p>Different views of input data (r, g, b) for images.</p>

<ul>
<li>Separate channels could be useful for different embeddings.</li>
</ul>

<hr />

<p>References:</p>

<ol>
<li>[Understanding Convolutional Neural Networks for NLP - Denny Britz]</li>
<li>Anecdote shared by Kanjun Qin, founder at Sourceress.</li>
</ol>


		
<div class="icons">
  <a href="https://github.com/mzio" target="_blank" class='icon'>
    <i class="fab fa-github icon"></i>
  </a>
  <a href="https://linkedin.com/in/michaelzhangxyz/" target="_blank" class='icon'>
    <i class="fab fa-linkedin-in icon"></i>
  </a>
  <a href="mailto:michael_zhang@college.harvard.edu" class='icon'>
    <i class="fas fa-envelope icon"></i>
  </a>
</div>



	</div>
</main>


        		<footer>
			<span>
			&copy; <time datetime="2021-08-12 12:26:01.973213 -0700 PDT m=&#43;0.157522107">2021</time>. Michael Zhang. H' 2020. 
			</span>
			<div class="container" style="padding-top: 5px; height: 200px; width: 71%;"></div>
			
			<script src="/js/life_contributions.js"></script>
			<script src="/js/life_contributions_commits.js"></script>
			<script type="text/javascript">
				var now = moment().endOf('day').toDate();
				var yearAgo = moment().startOf('day').subtract(1, 'year').toDate();
				var graph = lifeContributions()
				.data(commits)
				.selector('.container')
				.tooltipEnabled(true)
				.onClick(function (data) {
					console.log('data', data);
				});
				graph();  
			</script>
		</footer>

    </body>
</html>
